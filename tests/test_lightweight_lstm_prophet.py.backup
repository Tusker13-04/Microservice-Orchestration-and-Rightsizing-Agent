#!/usr/bin/env python3
"""
Lightweight LSTM + Prophet Pipeline Tests

Comprehensive TDD tests for the lightweight pipeline including:
- Data loading and preprocessing
- Prophet model training
- LSTM model training  
- Fusion prediction logic
- Model persistence and loading
- Error handling
"""

import os
import sys
import pytest
import tempfile
import shutil
import pandas as pd
import numpy as np
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock
import joblib

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from train_models.train_lightweight_lstm_prophet import LightweightLSTMProphetPipeline


class TestLightweightLSTMProphetPipeline:
    """Test the LightweightLSTMProphetPipeline class"""
    
    def setup_method(self):
        """Set up test environment"""
        self.temp_dir = tempfile.mkdtemp()
        self.data_dir = os.path.join(self.temp_dir, 'training_data')
        self.model_dir = os.path.join(self.temp_dir, 'models')
        os.makedirs(self.data_dir, exist_ok=True)
        os.makedirs(self.model_dir, exist_ok=True)
        
        # Create sample training data
        self.create_sample_data()
    
    def teardown_method(self):
        """Clean up test environment"""
        shutil.rmtree(self.temp_dir)
    
    def create_sample_data(self):
        """Create sample training data for testing"""
        # Create sample CSV file for frontend service
        data = {
            'timestamp': pd.date_range('2024-01-01', periods=100, freq='5min'),
            'cpu_cores_value': np.random.rand(100),
            'mem_bytes_value': np.random.rand(100) * 1000000,
            'net_rx_bytes_value': np.random.rand(100) * 100000,
            'net_tx_bytes_value': np.random.rand(100) * 100000,
            'pod_restarts_value': np.random.randint(0, 2, 100),
            'replica_count_value': np.random.randint(1, 5, 100),
            'load_users': np.random.randint(1, 100, 100)
        }
        
        df = pd.DataFrame(data)
        df.to_csv(
            os.path.join(self.data_dir, 'frontend_browsing_replicas_1_users_10.csv'),
            index=False
        )
    
    def test_pipeline_initialization(self):
        """Test that pipeline initializes correctly"""
        pipeline = LightweightLSTMProphetPipeline(
            data_dir=self.data_dir,
            model_dir=self.model_dir
        )
        
        assert pipeline.data_dir == self.data_dir
        assert pipeline.model_dir == self.model_dir
        assert pipeline.config is not None
    
    def test_load_training_data(self):
        """Test data loading functionality"""
        pipeline = LightweightLSTMProphetPipeline(
            data_dir=self.data_dir,
            model_dir=self.model_dir
        )
        
        data = pipeline._load_training_data('frontend')
        
        assert isinstance(data, pd.DataFrame)
        assert len(data) > 0
        assert 'cpu_cores_value' in data.columns
        assert 'timestamp' in data.columns
    
    def test_load_training_data_no_files(self):
        """Test data loading with no files available"""
        pipeline = LightweightLSTMProphetPipeline(
            data_dir=self.data_dir,
            model_dir=self.model_dir
        )
        
        with pytest.raises(ValueError, match="No training data files found"):
            pipeline._load_training_data('non_existent_service')
    
    def test_prepare_time_series_data(self):
        """Test time series data preparation"""
        pipeline = LightweightLSTMProphetPipeline(
            data_dir=self.data_dir,
            model_dir=self.model_dir
        )
        
        data = pipeline._load_training_data('frontend')
        X, y = pipeline._prepare_time_series_data(data)
        
        assert X.shape[0] == y.shape[0]
        assert 'cpu_target' in y.columns
        assert 'memory_target' in y.columns
        assert 'replica_target' in y.columns
    
    def test_create_prophet_model(self):
        """Test Prophet model creation"""
        pipeline = LightweightLSTMProphetPipeline(
            data_dir=self.data_dir,
            model_dir=self.model_dir
        )
        
        data = pipeline._load_training_data('frontend')
        X, y = pipeline._prepare_time_series_data(data)
        
        prophet_model = pipeline._create_prophet_model(X, y.iloc[:, 0])
        
        assert prophet_model is not None
        assert hasattr(prophet_model, 'predict')
    
    def test_create_lstm_model(self):
        """Test LSTM model creation"""
        pipeline = LightweightLSTMProphetPipeline(
            data_dir=self.data_dir,
            model_dir=self.model_dir
        )
        
        data = pipeline._load_training_data('frontend')
        X, y = pipeline._prepare_time_series_data(data)
        
        lstm_model = pipeline._create_lstm_model(X, y.iloc[:, 0].values)
        
        assert lstm_model is not None
        assert hasattr(lstm_model, 'predict')
    
    def test_fusion_prediction(self):
        """Test fusion prediction logic"""
        pipeline = LightweightLSTMProphetPipeline(
            data_dir=self.data_dir,
            model_dir=self.model_dir
        )
        
        # Mock predictions
        lstm_pred = np.array([0.5])
        prophet_pred = np.array([0.6])
        
        fusion_pred, confidence = pipeline._create_fusion_prediction(
            lstm_pred, prophet_pred
        )
        
        assert isinstance(fusion_pred, float)
        assert 0 <= confidence <= 1
    
    def test_train_single_service(self):
        """Test training a single service"""
        pipeline = LightweightLSTMProphetPipeline(
            data_dir=self.data_dir,
            model_dir=self.model_dir
        )
        
        pipeline.train_service('frontend')
        
        # Check that model file was created
        model_path = os.path.join(self.model_dir, 'frontend_lstm_prophet_pipeline.joblib')
        assert os.path.exists(model_path)
    
    def test_train_single_service_no_data(self):
        """Test training with no data available"""
        pipeline = LightweightLSTMProphetPipeline(
            data_dir=self.data_dir,
            model_dir=self.model_dir
        )
        
        with pytest.raises(ValueError):
            pipeline.train_service('non_existent')
    
    def test_save_pipeline(self):
        """Test saving the pipeline"""
        pipeline = LightweightLSTMProphetPipeline(
            data_dir=self.data_dir,
            model_dir=self.model_dir
        )
        
        # Create a mock pipeline object
        pipeline_obj = {
            'prophet_models': {},
            'lstm_models': {},
            'scaler_X': Mock(),
            'scaler_y': Mock(),
            'target_columns': ['cpu_target', 'memory_target', 'replica_target'],
            'feature_columns': ['cpu_cores_value', 'mem_bytes_value'],
            'data_shape': (100, 10),
            'pipeline_type': 'lightweight_lstm_prophet',
            'trained_at': pd.Timestamp.now().isoformat()
        }
        
        model_path = os.path.join(self.model_dir, 'frontend_lstm_prophet_pipeline.joblib')
        pipeline._save_pipeline(pipeline_obj, 'frontend')
        
        assert os.path.exists(model_path)
    
    def test_load_saved_pipeline(self):
        """Test loading a saved pipeline"""
        # Create and save a pipeline first
        pipeline = LightweightLSTMProphetPipeline(
            data_dir=self.data_dir,
            model_dir=self.model_dir
        )
        
        pipeline.train_service('frontend')
        
        # Now test loading
        model_path = os.path.join(self.model_dir, 'frontend_lstm_prophet_pipeline.joblib')
        loaded_pipeline = joblib.load(model_path)
        
        assert 'pipeline_type' in loaded_pipeline
        assert loaded_pipeline['pipeline_type'] == 'lightweight_lstm_prophet'
    
    def test_predict_with_trained_model(self):
        """Test making predictions with a trained model"""
        pipeline = LightweightLSTMProphetPipeline(
            data_dir=self.data_dir,
            model_dir=self.model_dir
        )
        
        # Train the model
        pipeline.train_service('frontend')
        
        # Create test data
        test_data = pd.DataFrame({
            'cpu_cores_value': [0.5],
            'mem_bytes_value': [100000],
            'net_rx_bytes_value': [10000],
            'net_tx_bytes_value': [10000],
            'pod_restarts_value': [0],
            'replica_count_value': [2],
            'load_users': [50]
        })
        
        # Load the model
        model_path = os.path.join(self.model_dir, 'frontend_lstm_prophet_pipeline.joblib')
        model = joblib.load(model_path)
        
        # Verify model has all required components
        assert 'prophet_models' in model
        assert 'lstm_models' in model
        assert 'scaler_X' in model
        assert 'scaler_y' in model
    
    def test_error_handling_invalid_service(self):
        """Test error handling for invalid service names"""
        pipeline = LightweightLSTMProphetPipeline(
            data_dir=self.data_dir,
            model_dir=self.model_dir
        )
        
        with pytest.raises(ValueError):
            pipeline.train_service('')
    
    def test_error_handling_corrupted_data(self):
        """Test error handling for corrupted data files"""
        # Create a corrupted CSV file
        bad_file = os.path.join(self.data_dir, 'frontend_browsing_replicas_2_users_10.csv')
        with open(bad_file, 'w') as f:
            f.write("not,a,valid,csv\ncorrupted,data,here\n")
        
        pipeline = LightweightLSTMProphetPipeline(
            data_dir=self.data_dir,
            model_dir=self.model_dir
        )
        
        # Should handle corrupted file gracefully
        try:
            data = pipeline._load_training_data('frontend')
            # Should still work with valid files
            assert isinstance(data, pd.DataFrame)
        except Exception as e:
            # Should raise a meaningful error
            assert 'error' in str(e).lower() or 'invalid' in str(e).lower()
    
    def test_prepare_time_series_missing_columns(self):
        """Test handling missing required columns"""
        pipeline = LightweightLSTMProphetPipeline(
            data_dir=self.data_dir,
            model_dir=self.model_dir
        )
        
        # Create data with missing columns
        bad_data = pd.DataFrame({
            'timestamp': pd.date_range('2024-01-01', periods=10, freq='5min'),
            'cpu_cores_value': np.random.rand(10)
        })
        
        with pytest.raises(KeyError):
            pipeline._prepare_time_series_data(bad_data)


class TestLightweightPipelineIntegration:
    """Integration tests for complete workflows"""
    
    def setup_method(self):
        """Set up test environment"""
        self.temp_dir = tempfile.mkdtemp()
        self.data_dir = os.path.join(self.temp_dir, 'training_data')
        self.model_dir = os.path.join(self.temp_dir, 'models')
        os.makedirs(self.data_dir, exist_ok=True)
        os.makedirs(self.model_dir, exist_ok=True)
        
        # Create comprehensive sample data
        self.create_sample_data()
    
    def teardown_method(self):
        """Clean up test environment"""
        shutil.rmtree(self.temp_dir)
    
    def create_sample_data(self):
        """Create comprehensive sample data"""
        for i in range(1, 4):  # Create 3 replica scenarios
            data = {
                'timestamp': pd.date_range('2024-01-01', periods=50, freq='5min'),
                'cpu_cores_value': np.random.rand(50),
                'mem_bytes_value': np.random.rand(50) * 1000000,
                'net_rx_bytes_value': np.random.rand(50) * 100000,
                'net_tx_bytes_value': np.random.rand(50) * 100000,
                'pod_restarts_value': np.random.randint(0, 2, 50),
                'replica_count_value': np.full(50, i),
                'load_users': np.random.randint(1, 100, 50)
            }
            
            df = pd.DataFrame(data)
            df.to_csv(
                os.path.join(self.data_dir, f'frontend_browsing_replicas_{i}_users_{i*10}.csv'),
                index=False
            )
    
    def test_end_to_end_training_workflow(self):
        """Test complete training workflow"""
        pipeline = LightweightLSTMProphetPipeline(
            data_dir=self.data_dir,
            model_dir=self.model_dir
        )
        
        # Train the model
        pipeline.train_service('frontend')
        
        # Verify model exists
        model_path = os.path.join(self.model_dir, 'frontend_lstm_prophet_pipeline.joblib')
        assert os.path.exists(model_path)
        
        # Verify model is loadable
        model = joblib.load(model_path)
        assert 'pipeline_type' in model
        assert 'trained_at' in model
    
    def test_training_multiple_services(self):
        """Test training multiple services sequentially"""
        # Create data for multiple services
        for service in ['frontend', 'cartservice']:
            service_dir = os.path.join(self.data_dir, f'{service}')
            for i in range(1, 3):
                data = {
                    'timestamp': pd.date_range('2024-01-01', periods=30, freq='5min'),
                    'cpu_cores_value': np.random.rand(30),
                    'mem_bytes_value': np.random.rand(30) * 1000000,
                    'net_rx_bytes_value': np.random.rand(30) * 100000,
                    'net_tx_bytes_value': np.random.rand(30) * 100000,
                    'pod_restarts_value': np.random.randint(0, 1, 30),
                    'replica_count_value': np.full(30, i),
                    'load_users': np.random.randint(1, 50, 30)
                }
                df = pd.DataFrame(data)
                df.to_csv(
                    os.path.join(self.data_dir, f'{service}_browsing_replicas_{i}_users_10.csv'),
                    index=False
                )
        
        pipeline = LightweightLSTMProphetPipeline(
            data_dir=self.data_dir,
            model_dir=self.model_dir
        )
        
        # Train both services
        pipeline.train_service('frontend')
        pipeline.train_service('cartservice')
        
        # Verify both models exist
        assert os.path.exists(os.path.join(self.model_dir, 'frontend_lstm_prophet_pipeline.joblib'))
        assert os.path.exists(os.path.join(self.model_dir, 'cartservice_lstm_prophet_pipeline.joblib'))


if __name__ == '__main__':
    pytest.main([__file__, '-v'])

